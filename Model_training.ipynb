{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwWt5WIC9xAq",
        "outputId": "5e72833f-c71e-4a80-eeea-9ddf4090b324"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras import layers, models\n"
      ],
      "metadata": {
        "id": "2tuPhLGx94u5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# Load dataset\n",
        "data_path = '/content/drive/MyDrive/IMDB_CSV/gt.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# Preprocess images\n",
        "image_data = []\n",
        "labels = []\n",
        "\n",
        "# Loop through the data and preprocess images\n",
        "for index, row in data.iterrows():\n",
        "    img_url = row['label']\n",
        "    age = row['score']\n",
        "\n",
        "    try:\n",
        "        # Load image from URL\n",
        "        response = requests.get(img_url)\n",
        "        img = cv2.imdecode(np.frombuffer(response.content, np.uint8), -1)\n",
        "\n",
        "        if img is not None:\n",
        "            # Resize image to a fixed size\n",
        "            img = cv2.resize(img, (64, 64))\n",
        "\n",
        "            # Convert grayscale images to RGB\n",
        "            if len(img.shape) == 2:\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "            # Append image and label to lists\n",
        "            image_data.append(img)\n",
        "            labels.append(age)\n",
        "        else:\n",
        "            print(f\"Error loading image: {img_url}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading image: {img_url}, {e}\")\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "image_data = np.array(image_data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Normalize images\n",
        "image_data = image_data / 255.0\n",
        "\n"
      ],
      "metadata": {
        "id": "aK5rNY30-C74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(image_data, labels, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "hqVD3vx2-3E9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "ZTyPReYtmF2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define the number of models in the ensemble\n",
        "num_models = 5\n",
        "models = []\n",
        "\n",
        "# Create instances of the CNN model\n",
        "for _ in range(num_models):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "    models.append(model)\n"
      ],
      "metadata": {
        "id": "_2oSauJq-5fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 30\n",
        "\n",
        "# Train each model on different subsets of the training data\n",
        "for i, model in enumerate(models):\n",
        "    print(f\"Training Model {i + 1}\")\n",
        "    model.fit(\n",
        "        datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "        steps_per_epoch=len(X_train) / batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_data=(X_test, y_test)\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5JBsvlD-8_z",
        "outputId": "c47d7dda-fb43-4619-aa20-3a388130d94d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Model 1\n",
            "Epoch 1/30\n",
            "228/228 [==============================] - 71s 304ms/step - loss: 411.7746 - mae: 16.8876 - val_loss: 326.1116 - val_mae: 15.6520\n",
            "Epoch 2/30\n",
            "228/228 [==============================] - 69s 303ms/step - loss: 348.1898 - mae: 15.8194 - val_loss: 332.5763 - val_mae: 15.5196\n",
            "Epoch 3/30\n",
            "228/228 [==============================] - 69s 303ms/step - loss: 345.6618 - mae: 15.6895 - val_loss: 301.4508 - val_mae: 14.9487\n",
            "Epoch 4/30\n",
            "228/228 [==============================] - 69s 304ms/step - loss: 336.4678 - mae: 15.4719 - val_loss: 305.7832 - val_mae: 15.0794\n",
            "Epoch 5/30\n",
            "228/228 [==============================] - 74s 326ms/step - loss: 330.1015 - mae: 15.3434 - val_loss: 300.9243 - val_mae: 14.8969\n",
            "Epoch 6/30\n",
            "228/228 [==============================] - 70s 305ms/step - loss: 329.3355 - mae: 15.2666 - val_loss: 313.5413 - val_mae: 15.0514\n",
            "Epoch 7/30\n",
            "228/228 [==============================] - 69s 303ms/step - loss: 318.3592 - mae: 15.0449 - val_loss: 294.0895 - val_mae: 14.7254\n",
            "Epoch 8/30\n",
            "228/228 [==============================] - 71s 310ms/step - loss: 313.5835 - mae: 14.9220 - val_loss: 297.1493 - val_mae: 14.6795\n",
            "Epoch 9/30\n",
            "228/228 [==============================] - 70s 303ms/step - loss: 320.0204 - mae: 15.0397 - val_loss: 296.6350 - val_mae: 14.7696\n",
            "Epoch 10/30\n",
            "228/228 [==============================] - 68s 299ms/step - loss: 314.4904 - mae: 14.9149 - val_loss: 292.5399 - val_mae: 14.5293\n",
            "Epoch 11/30\n",
            "228/228 [==============================] - 71s 310ms/step - loss: 309.5450 - mae: 14.8030 - val_loss: 300.1762 - val_mae: 14.7147\n",
            "Epoch 12/30\n",
            "228/228 [==============================] - 69s 302ms/step - loss: 315.1473 - mae: 14.9369 - val_loss: 289.4081 - val_mae: 14.4334\n",
            "Epoch 13/30\n",
            "228/228 [==============================] - 69s 299ms/step - loss: 310.5649 - mae: 14.7906 - val_loss: 288.7192 - val_mae: 14.4954\n",
            "Epoch 14/30\n",
            "228/228 [==============================] - 68s 299ms/step - loss: 312.1910 - mae: 14.8584 - val_loss: 284.6755 - val_mae: 14.3691\n",
            "Epoch 15/30\n",
            "228/228 [==============================] - 66s 287ms/step - loss: 311.6638 - mae: 14.7932 - val_loss: 291.8782 - val_mae: 14.4647\n",
            "Epoch 16/30\n",
            "228/228 [==============================] - 65s 284ms/step - loss: 308.6236 - mae: 14.7143 - val_loss: 282.7827 - val_mae: 14.1693\n",
            "Epoch 17/30\n",
            "228/228 [==============================] - 68s 295ms/step - loss: 307.6065 - mae: 14.7042 - val_loss: 299.6338 - val_mae: 14.4111\n",
            "Epoch 18/30\n",
            "228/228 [==============================] - 67s 293ms/step - loss: 303.8862 - mae: 14.6121 - val_loss: 296.6330 - val_mae: 14.5648\n",
            "Epoch 19/30\n",
            "228/228 [==============================] - 68s 295ms/step - loss: 307.2737 - mae: 14.6968 - val_loss: 282.2425 - val_mae: 14.1277\n",
            "Epoch 20/30\n",
            "228/228 [==============================] - 65s 286ms/step - loss: 308.0663 - mae: 14.6872 - val_loss: 281.7366 - val_mae: 14.1519\n",
            "Epoch 21/30\n",
            "228/228 [==============================] - 68s 296ms/step - loss: 301.4268 - mae: 14.4958 - val_loss: 298.7653 - val_mae: 14.4418\n",
            "Epoch 22/30\n",
            "228/228 [==============================] - 69s 301ms/step - loss: 302.4631 - mae: 14.5250 - val_loss: 280.5430 - val_mae: 14.1836\n",
            "Epoch 23/30\n",
            "228/228 [==============================] - 65s 284ms/step - loss: 301.1198 - mae: 14.5289 - val_loss: 285.0832 - val_mae: 14.2082\n",
            "Epoch 24/30\n",
            "228/228 [==============================] - 67s 292ms/step - loss: 298.4143 - mae: 14.4427 - val_loss: 278.8822 - val_mae: 13.9679\n",
            "Epoch 25/30\n",
            "228/228 [==============================] - 66s 289ms/step - loss: 298.5806 - mae: 14.3691 - val_loss: 277.8112 - val_mae: 13.9205\n",
            "Epoch 26/30\n",
            "228/228 [==============================] - 66s 289ms/step - loss: 296.0215 - mae: 14.3013 - val_loss: 289.5831 - val_mae: 14.1790\n",
            "Epoch 27/30\n",
            "228/228 [==============================] - 68s 298ms/step - loss: 290.5542 - mae: 14.1703 - val_loss: 276.4668 - val_mae: 13.8886\n",
            "Epoch 28/30\n",
            "228/228 [==============================] - 68s 297ms/step - loss: 294.5732 - mae: 14.3111 - val_loss: 272.0341 - val_mae: 13.6760\n",
            "Epoch 29/30\n",
            "228/228 [==============================] - 68s 295ms/step - loss: 287.6890 - mae: 14.1019 - val_loss: 285.2410 - val_mae: 13.9858\n",
            "Epoch 30/30\n",
            "228/228 [==============================] - 68s 297ms/step - loss: 283.3546 - mae: 14.0155 - val_loss: 278.9478 - val_mae: 13.8709\n",
            "Training Model 2\n",
            "Epoch 1/30\n",
            "228/228 [==============================] - 73s 313ms/step - loss: 420.8358 - mae: 16.9963 - val_loss: 352.6542 - val_mae: 16.1332\n",
            "Epoch 2/30\n",
            "228/228 [==============================] - 65s 286ms/step - loss: 360.1380 - mae: 16.0663 - val_loss: 312.0117 - val_mae: 15.2561\n",
            "Epoch 3/30\n",
            "228/228 [==============================] - 66s 290ms/step - loss: 346.4289 - mae: 15.7145 - val_loss: 305.9397 - val_mae: 15.0060\n",
            "Epoch 4/30\n",
            "228/228 [==============================] - 67s 295ms/step - loss: 336.0392 - mae: 15.4379 - val_loss: 303.2166 - val_mae: 14.9239\n",
            "Epoch 5/30\n",
            "228/228 [==============================] - 65s 285ms/step - loss: 331.6781 - mae: 15.3769 - val_loss: 298.4671 - val_mae: 14.8861\n",
            "Epoch 6/30\n",
            "228/228 [==============================] - 63s 277ms/step - loss: 323.3929 - mae: 15.1323 - val_loss: 296.3527 - val_mae: 14.6286\n",
            "Epoch 7/30\n",
            "228/228 [==============================] - 68s 298ms/step - loss: 322.2541 - mae: 15.1199 - val_loss: 316.4381 - val_mae: 15.1254\n",
            "Epoch 8/30\n",
            "228/228 [==============================] - 66s 290ms/step - loss: 320.9285 - mae: 15.0763 - val_loss: 289.9958 - val_mae: 14.4841\n",
            "Epoch 9/30\n",
            "228/228 [==============================] - 66s 287ms/step - loss: 326.3759 - mae: 15.1992 - val_loss: 302.2994 - val_mae: 14.8627\n",
            "Epoch 10/30\n",
            "228/228 [==============================] - 68s 298ms/step - loss: 318.8089 - mae: 15.0271 - val_loss: 294.9292 - val_mae: 14.7280\n",
            "Epoch 11/30\n",
            "228/228 [==============================] - 68s 298ms/step - loss: 320.4261 - mae: 15.0827 - val_loss: 290.5785 - val_mae: 14.6049\n",
            "Epoch 12/30\n",
            "228/228 [==============================] - 65s 283ms/step - loss: 315.0786 - mae: 14.8570 - val_loss: 284.1403 - val_mae: 14.3034\n",
            "Epoch 13/30\n",
            "228/228 [==============================] - 68s 298ms/step - loss: 307.6225 - mae: 14.7325 - val_loss: 306.4488 - val_mae: 14.6681\n",
            "Epoch 14/30\n",
            "228/228 [==============================] - 67s 291ms/step - loss: 318.0330 - mae: 14.9691 - val_loss: 295.2816 - val_mae: 14.7456\n",
            "Epoch 15/30\n",
            "228/228 [==============================] - 69s 300ms/step - loss: 312.4246 - mae: 14.8070 - val_loss: 289.1865 - val_mae: 14.3994\n",
            "Epoch 16/30\n",
            "228/228 [==============================] - 69s 302ms/step - loss: 312.0490 - mae: 14.7766 - val_loss: 294.3329 - val_mae: 14.5930\n",
            "Epoch 17/30\n",
            "228/228 [==============================] - 66s 288ms/step - loss: 310.2153 - mae: 14.7772 - val_loss: 283.1877 - val_mae: 14.2588\n",
            "Epoch 18/30\n",
            "228/228 [==============================] - 70s 303ms/step - loss: 306.5838 - mae: 14.6998 - val_loss: 288.1407 - val_mae: 14.3420\n",
            "Epoch 19/30\n",
            "228/228 [==============================] - 70s 304ms/step - loss: 303.2643 - mae: 14.5848 - val_loss: 289.0049 - val_mae: 14.3265\n",
            "Epoch 20/30\n",
            "228/228 [==============================] - 69s 299ms/step - loss: 306.0731 - mae: 14.6603 - val_loss: 285.1847 - val_mae: 14.3386\n",
            "Epoch 21/30\n",
            "228/228 [==============================] - 66s 289ms/step - loss: 305.5994 - mae: 14.6354 - val_loss: 276.8616 - val_mae: 14.0306\n",
            "Epoch 22/30\n",
            "228/228 [==============================] - 65s 286ms/step - loss: 302.4320 - mae: 14.5302 - val_loss: 288.0312 - val_mae: 14.2707\n",
            "Epoch 23/30\n",
            "228/228 [==============================] - 63s 277ms/step - loss: 302.2836 - mae: 14.5099 - val_loss: 285.2812 - val_mae: 14.2018\n",
            "Epoch 24/30\n",
            "228/228 [==============================] - 68s 296ms/step - loss: 303.9172 - mae: 14.6087 - val_loss: 271.7404 - val_mae: 13.8299\n",
            "Epoch 25/30\n",
            "228/228 [==============================] - 69s 301ms/step - loss: 294.4935 - mae: 14.3500 - val_loss: 281.0300 - val_mae: 14.0870\n",
            "Epoch 26/30\n",
            "228/228 [==============================] - 67s 295ms/step - loss: 297.3693 - mae: 14.3665 - val_loss: 279.7636 - val_mae: 14.1139\n",
            "Epoch 27/30\n",
            "228/228 [==============================] - 71s 310ms/step - loss: 300.1490 - mae: 14.4694 - val_loss: 280.2239 - val_mae: 13.9970\n",
            "Epoch 28/30\n",
            "228/228 [==============================] - 71s 311ms/step - loss: 295.9114 - mae: 14.2675 - val_loss: 281.9678 - val_mae: 13.9469\n",
            "Epoch 29/30\n",
            "228/228 [==============================] - 71s 307ms/step - loss: 290.7170 - mae: 14.2417 - val_loss: 274.1238 - val_mae: 13.8571\n",
            "Epoch 30/30\n",
            "228/228 [==============================] - 64s 280ms/step - loss: 299.0009 - mae: 14.3638 - val_loss: 279.2472 - val_mae: 14.0071\n",
            "Training Model 3\n",
            "Epoch 1/30\n",
            "228/228 [==============================] - 69s 298ms/step - loss: 425.9280 - mae: 17.1176 - val_loss: 334.3718 - val_mae: 15.6933\n",
            "Epoch 2/30\n",
            "228/228 [==============================] - 68s 298ms/step - loss: 360.8427 - mae: 15.9912 - val_loss: 307.6138 - val_mae: 15.1274\n",
            "Epoch 3/30\n",
            "228/228 [==============================] - 66s 287ms/step - loss: 360.1322 - mae: 15.9607 - val_loss: 307.5187 - val_mae: 15.0889\n",
            "Epoch 4/30\n",
            "228/228 [==============================] - 71s 310ms/step - loss: 341.2982 - mae: 15.5424 - val_loss: 297.7543 - val_mae: 14.8521\n",
            "Epoch 5/30\n",
            "228/228 [==============================] - 67s 293ms/step - loss: 344.4406 - mae: 15.6189 - val_loss: 313.8685 - val_mae: 15.0345\n",
            "Epoch 6/30\n",
            "228/228 [==============================] - 67s 291ms/step - loss: 331.6085 - mae: 15.2366 - val_loss: 293.1555 - val_mae: 14.7387\n",
            "Epoch 7/30\n",
            "228/228 [==============================] - 69s 301ms/step - loss: 332.2639 - mae: 15.3420 - val_loss: 292.1282 - val_mae: 14.6030\n",
            "Epoch 8/30\n",
            "228/228 [==============================] - 65s 282ms/step - loss: 331.9072 - mae: 15.2848 - val_loss: 304.9088 - val_mae: 14.8865\n",
            "Epoch 9/30\n",
            "228/228 [==============================] - 65s 282ms/step - loss: 333.9319 - mae: 15.3552 - val_loss: 290.1065 - val_mae: 14.5505\n",
            "Epoch 10/30\n",
            "228/228 [==============================] - 69s 301ms/step - loss: 325.8853 - mae: 15.1421 - val_loss: 297.7410 - val_mae: 14.7475\n",
            "Epoch 11/30\n",
            "228/228 [==============================] - 63s 277ms/step - loss: 319.8658 - mae: 14.9552 - val_loss: 289.7045 - val_mae: 14.5483\n",
            "Epoch 12/30\n",
            "228/228 [==============================] - 67s 291ms/step - loss: 324.3915 - mae: 15.1284 - val_loss: 285.1354 - val_mae: 14.3556\n",
            "Epoch 13/30\n",
            "228/228 [==============================] - 68s 296ms/step - loss: 315.2936 - mae: 14.9045 - val_loss: 294.9495 - val_mae: 14.5637\n",
            "Epoch 14/30\n",
            "228/228 [==============================] - 65s 284ms/step - loss: 313.8000 - mae: 14.8714 - val_loss: 287.9881 - val_mae: 14.4249\n",
            "Epoch 15/30\n",
            "228/228 [==============================] - 67s 291ms/step - loss: 312.2440 - mae: 14.7421 - val_loss: 290.1541 - val_mae: 14.3931\n",
            "Epoch 16/30\n",
            "228/228 [==============================] - 65s 285ms/step - loss: 315.0603 - mae: 14.8967 - val_loss: 298.1024 - val_mae: 14.5287\n",
            "Epoch 17/30\n",
            "228/228 [==============================] - 67s 294ms/step - loss: 312.2101 - mae: 14.7746 - val_loss: 289.1041 - val_mae: 14.4295\n",
            "Epoch 18/30\n",
            "228/228 [==============================] - 65s 283ms/step - loss: 307.7635 - mae: 14.6128 - val_loss: 279.6880 - val_mae: 14.0985\n",
            "Epoch 19/30\n",
            "228/228 [==============================] - 67s 293ms/step - loss: 311.5115 - mae: 14.7209 - val_loss: 285.9308 - val_mae: 14.1925\n",
            "Epoch 20/30\n",
            "228/228 [==============================] - 67s 294ms/step - loss: 308.6742 - mae: 14.6149 - val_loss: 280.9257 - val_mae: 14.0671\n",
            "Epoch 21/30\n",
            "228/228 [==============================] - 65s 283ms/step - loss: 307.1733 - mae: 14.6353 - val_loss: 288.1861 - val_mae: 14.1416\n",
            "Epoch 22/30\n",
            "228/228 [==============================] - 66s 289ms/step - loss: 311.5650 - mae: 14.6674 - val_loss: 284.5132 - val_mae: 14.2423\n",
            "Epoch 23/30\n",
            "228/228 [==============================] - 67s 294ms/step - loss: 307.5712 - mae: 14.5981 - val_loss: 279.7924 - val_mae: 14.0262\n",
            "Epoch 24/30\n",
            "228/228 [==============================] - 66s 286ms/step - loss: 297.3733 - mae: 14.3087 - val_loss: 272.9381 - val_mae: 13.8893\n",
            "Epoch 25/30\n",
            "228/228 [==============================] - 65s 285ms/step - loss: 306.1017 - mae: 14.5655 - val_loss: 280.5650 - val_mae: 14.0556\n",
            "Epoch 26/30\n",
            "228/228 [==============================] - 66s 287ms/step - loss: 299.5557 - mae: 14.3540 - val_loss: 275.8098 - val_mae: 13.8752\n",
            "Epoch 27/30\n",
            "228/228 [==============================] - 64s 278ms/step - loss: 299.8371 - mae: 14.3838 - val_loss: 285.5336 - val_mae: 14.0850\n",
            "Epoch 28/30\n",
            "228/228 [==============================] - 67s 292ms/step - loss: 296.9117 - mae: 14.3075 - val_loss: 282.4747 - val_mae: 14.0807\n",
            "Epoch 29/30\n",
            "228/228 [==============================] - 68s 294ms/step - loss: 296.0681 - mae: 14.2711 - val_loss: 283.8206 - val_mae: 14.0244\n",
            "Epoch 30/30\n",
            "228/228 [==============================] - 67s 291ms/step - loss: 295.1976 - mae: 14.2649 - val_loss: 276.2201 - val_mae: 13.8403\n",
            "Training Model 4\n",
            "Epoch 1/30\n",
            "228/228 [==============================] - 71s 304ms/step - loss: 425.9791 - mae: 17.0911 - val_loss: 328.9053 - val_mae: 15.6186\n",
            "Epoch 2/30\n",
            "228/228 [==============================] - 74s 321ms/step - loss: 362.7888 - mae: 16.0248 - val_loss: 306.6260 - val_mae: 15.1614\n",
            "Epoch 3/30\n",
            "228/228 [==============================] - 69s 302ms/step - loss: 345.4459 - mae: 15.6850 - val_loss: 304.8994 - val_mae: 15.0266\n",
            "Epoch 4/30\n",
            "228/228 [==============================] - 70s 305ms/step - loss: 343.0080 - mae: 15.5952 - val_loss: 294.2561 - val_mae: 14.7623\n",
            "Epoch 5/30\n",
            "228/228 [==============================] - 74s 325ms/step - loss: 333.6396 - mae: 15.3493 - val_loss: 295.7506 - val_mae: 14.8140\n",
            "Epoch 6/30\n",
            "228/228 [==============================] - 70s 306ms/step - loss: 328.4120 - mae: 15.2396 - val_loss: 318.0621 - val_mae: 15.1069\n",
            "Epoch 7/30\n",
            "228/228 [==============================] - 70s 303ms/step - loss: 329.7157 - mae: 15.2322 - val_loss: 290.6018 - val_mae: 14.6758\n",
            "Epoch 8/30\n",
            "228/228 [==============================] - 72s 314ms/step - loss: 324.9791 - mae: 15.1877 - val_loss: 286.8634 - val_mae: 14.4908\n",
            "Epoch 9/30\n",
            "228/228 [==============================] - 67s 294ms/step - loss: 323.1827 - mae: 15.1065 - val_loss: 294.9940 - val_mae: 14.7165\n",
            "Epoch 10/30\n",
            "228/228 [==============================] - 67s 295ms/step - loss: 320.3909 - mae: 14.9669 - val_loss: 285.9586 - val_mae: 14.3959\n",
            "Epoch 11/30\n",
            "228/228 [==============================] - 72s 313ms/step - loss: 320.5811 - mae: 15.0395 - val_loss: 287.4472 - val_mae: 14.5428\n",
            "Epoch 12/30\n",
            "228/228 [==============================] - 70s 306ms/step - loss: 325.9635 - mae: 15.1337 - val_loss: 290.2228 - val_mae: 14.5056\n",
            "Epoch 13/30\n",
            "228/228 [==============================] - 70s 305ms/step - loss: 319.4894 - mae: 14.9883 - val_loss: 319.9723 - val_mae: 15.1941\n",
            "Epoch 14/30\n",
            "228/228 [==============================] - 72s 317ms/step - loss: 321.8342 - mae: 15.0173 - val_loss: 287.0166 - val_mae: 14.2566\n",
            "Epoch 15/30\n",
            "228/228 [==============================] - 65s 286ms/step - loss: 316.8982 - mae: 14.8950 - val_loss: 279.4615 - val_mae: 14.2105\n",
            "Epoch 16/30\n",
            "228/228 [==============================] - 69s 303ms/step - loss: 317.3860 - mae: 14.9329 - val_loss: 287.1492 - val_mae: 14.3788\n",
            "Epoch 17/30\n",
            "228/228 [==============================] - 72s 313ms/step - loss: 315.9106 - mae: 14.9045 - val_loss: 279.6620 - val_mae: 14.0118\n",
            "Epoch 18/30\n",
            "228/228 [==============================] - 69s 301ms/step - loss: 314.2600 - mae: 14.8208 - val_loss: 281.5057 - val_mae: 14.2398\n",
            "Epoch 19/30\n",
            "228/228 [==============================] - 68s 297ms/step - loss: 308.5202 - mae: 14.6479 - val_loss: 283.6372 - val_mae: 14.2454\n",
            "Epoch 20/30\n",
            "228/228 [==============================] - 69s 300ms/step - loss: 311.7773 - mae: 14.7147 - val_loss: 287.9682 - val_mae: 14.4004\n",
            "Epoch 21/30\n",
            "228/228 [==============================] - 69s 301ms/step - loss: 309.9166 - mae: 14.6937 - val_loss: 282.8769 - val_mae: 14.2435\n",
            "Epoch 22/30\n",
            "228/228 [==============================] - 70s 306ms/step - loss: 306.5413 - mae: 14.5843 - val_loss: 280.7569 - val_mae: 14.1245\n",
            "Epoch 23/30\n",
            "228/228 [==============================] - 72s 316ms/step - loss: 305.0313 - mae: 14.5311 - val_loss: 277.0940 - val_mae: 13.9337\n",
            "Epoch 24/30\n",
            "228/228 [==============================] - 69s 301ms/step - loss: 304.1480 - mae: 14.5367 - val_loss: 277.2912 - val_mae: 14.0762\n",
            "Epoch 25/30\n",
            "228/228 [==============================] - 71s 308ms/step - loss: 306.4651 - mae: 14.5571 - val_loss: 281.1622 - val_mae: 14.1518\n",
            "Epoch 26/30\n",
            "228/228 [==============================] - 69s 302ms/step - loss: 305.1974 - mae: 14.5901 - val_loss: 281.9276 - val_mae: 14.1849\n",
            "Epoch 27/30\n",
            "228/228 [==============================] - 72s 313ms/step - loss: 300.5740 - mae: 14.3974 - val_loss: 288.0876 - val_mae: 14.2273\n",
            "Epoch 28/30\n",
            "228/228 [==============================] - 67s 292ms/step - loss: 301.0373 - mae: 14.4425 - val_loss: 275.7561 - val_mae: 13.9304\n",
            "Epoch 29/30\n",
            "228/228 [==============================] - 72s 316ms/step - loss: 295.6534 - mae: 14.2810 - val_loss: 285.1769 - val_mae: 14.1829\n",
            "Epoch 30/30\n",
            "228/228 [==============================] - 69s 302ms/step - loss: 300.0228 - mae: 14.3346 - val_loss: 270.3769 - val_mae: 13.7872\n",
            "Training Model 5\n",
            "Epoch 1/30\n",
            "228/228 [==============================] - 71s 302ms/step - loss: 424.9544 - mae: 17.1281 - val_loss: 343.6573 - val_mae: 15.8726\n",
            "Epoch 2/30\n",
            "228/228 [==============================] - 71s 309ms/step - loss: 362.6742 - mae: 15.9742 - val_loss: 323.8120 - val_mae: 15.4358\n",
            "Epoch 3/30\n",
            "228/228 [==============================] - 66s 290ms/step - loss: 348.4225 - mae: 15.6671 - val_loss: 340.7064 - val_mae: 15.6382\n",
            "Epoch 4/30\n",
            "228/228 [==============================] - 70s 304ms/step - loss: 348.9760 - mae: 15.7645 - val_loss: 300.7928 - val_mae: 14.9680\n",
            "Epoch 5/30\n",
            "228/228 [==============================] - 70s 304ms/step - loss: 341.9426 - mae: 15.5608 - val_loss: 333.5788 - val_mae: 15.4606\n",
            "Epoch 6/30\n",
            "228/228 [==============================] - 66s 288ms/step - loss: 330.5996 - mae: 15.2752 - val_loss: 291.2787 - val_mae: 14.6478\n",
            "Epoch 7/30\n",
            "228/228 [==============================] - 67s 294ms/step - loss: 327.6248 - mae: 15.2575 - val_loss: 326.9225 - val_mae: 15.2831\n",
            "Epoch 8/30\n",
            "228/228 [==============================] - 69s 300ms/step - loss: 328.4200 - mae: 15.2132 - val_loss: 292.0022 - val_mae: 14.6661\n",
            "Epoch 9/30\n",
            "228/228 [==============================] - 69s 301ms/step - loss: 325.5934 - mae: 15.1700 - val_loss: 298.8883 - val_mae: 14.7916\n",
            "Epoch 10/30\n",
            "228/228 [==============================] - 68s 298ms/step - loss: 329.3437 - mae: 15.2724 - val_loss: 289.8956 - val_mae: 14.5275\n",
            "Epoch 11/30\n",
            "228/228 [==============================] - 73s 317ms/step - loss: 325.3186 - mae: 15.1319 - val_loss: 288.6621 - val_mae: 14.5517\n",
            "Epoch 12/30\n",
            "228/228 [==============================] - 66s 289ms/step - loss: 321.3526 - mae: 15.0673 - val_loss: 288.6159 - val_mae: 14.5783\n",
            "Epoch 13/30\n",
            "228/228 [==============================] - 66s 289ms/step - loss: 318.1012 - mae: 14.9333 - val_loss: 287.7399 - val_mae: 14.5359\n",
            "Epoch 14/30\n",
            "228/228 [==============================] - 68s 297ms/step - loss: 325.0019 - mae: 15.1380 - val_loss: 284.7452 - val_mae: 14.3803\n",
            "Epoch 15/30\n",
            "228/228 [==============================] - 70s 305ms/step - loss: 318.0418 - mae: 14.9167 - val_loss: 285.8844 - val_mae: 14.4134\n",
            "Epoch 16/30\n",
            "228/228 [==============================] - 70s 304ms/step - loss: 322.8580 - mae: 15.0089 - val_loss: 294.0302 - val_mae: 14.5004\n",
            "Epoch 17/30\n",
            "228/228 [==============================] - 68s 297ms/step - loss: 317.7245 - mae: 14.9640 - val_loss: 294.2023 - val_mae: 14.6047\n",
            "Epoch 18/30\n",
            "228/228 [==============================] - 71s 309ms/step - loss: 312.4771 - mae: 14.7491 - val_loss: 280.3531 - val_mae: 14.2006\n",
            "Epoch 19/30\n",
            "228/228 [==============================] - 67s 295ms/step - loss: 313.2836 - mae: 14.7978 - val_loss: 279.9192 - val_mae: 14.1789\n",
            "Epoch 20/30\n",
            "228/228 [==============================] - 68s 296ms/step - loss: 308.9543 - mae: 14.7512 - val_loss: 279.0986 - val_mae: 14.0485\n",
            "Epoch 21/30\n",
            "228/228 [==============================] - 70s 307ms/step - loss: 308.7270 - mae: 14.6715 - val_loss: 307.0916 - val_mae: 14.6977\n",
            "Epoch 22/30\n",
            "228/228 [==============================] - 64s 277ms/step - loss: 310.4869 - mae: 14.7117 - val_loss: 279.5648 - val_mae: 14.0784\n",
            "Epoch 23/30\n",
            "228/228 [==============================] - 66s 290ms/step - loss: 307.2783 - mae: 14.6286 - val_loss: 274.2626 - val_mae: 13.9175\n",
            "Epoch 24/30\n",
            "228/228 [==============================] - 68s 295ms/step - loss: 310.3732 - mae: 14.6898 - val_loss: 276.5489 - val_mae: 13.9743\n",
            "Epoch 25/30\n",
            "228/228 [==============================] - 66s 288ms/step - loss: 312.8456 - mae: 14.7155 - val_loss: 279.1619 - val_mae: 13.9733\n",
            "Epoch 26/30\n",
            "228/228 [==============================] - 68s 295ms/step - loss: 304.1969 - mae: 14.5028 - val_loss: 288.1043 - val_mae: 14.3557\n",
            "Epoch 27/30\n",
            "228/228 [==============================] - 67s 294ms/step - loss: 301.4114 - mae: 14.4790 - val_loss: 274.5163 - val_mae: 13.9243\n",
            "Epoch 28/30\n",
            "228/228 [==============================] - 70s 304ms/step - loss: 302.5301 - mae: 14.4675 - val_loss: 280.3067 - val_mae: 14.0672\n",
            "Epoch 29/30\n",
            "228/228 [==============================] - 68s 296ms/step - loss: 300.6660 - mae: 14.4265 - val_loss: 273.2996 - val_mae: 13.8573\n",
            "Epoch 30/30\n",
            "228/228 [==============================] - 68s 297ms/step - loss: 303.2566 - mae: 14.4442 - val_loss: 273.9120 - val_mae: 13.8182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Predict age labels for test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate mean absolute error (MAE)\n",
        "mae = np.mean(np.abs(y_pred.flatten() - y_test))\n",
        "\n",
        "# Calculate accuracy (percentage of predictions within a tolerance)\n",
        "tolerance = 5  # Define tolerance for correct predictions\n",
        "correct_predictions = np.sum(np.abs(y_pred.flatten() - y_test) <= tolerance)\n",
        "total_predictions = len(y_test)\n",
        "accuracy = (correct_predictions / total_predictions) * 100\n",
        "\n",
        "print(\"Test Mean Absolute Error:\", mae)\n",
        "print(\"Test Accuracy:\", accuracy, \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-etxH0D-_r-",
        "outputId": "b778e9e6-5dcc-441c-f57a-dcd58761c17b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 4s 69ms/step\n",
            "Test Mean Absolute Error: 13.818204679645476\n",
            "Test Accuracy: 19.672131147540984 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean absolute error (MAE)\n",
        "mae = np.mean(np.abs(y_pred.flatten() - y_test))\n",
        "\n",
        "# Print actual and adjusted predicted age labels for a few samples\n",
        "num_samples = 10  # Number of samples to display\n",
        "for i in range(num_samples):\n",
        "    print(\"Sample\", i+1)\n",
        "    print(\"Actual Age:\", y_test[i])\n",
        "    adjusted_age = round(y_pred[i][0] + mae)  # Adjusted predicted age\n",
        "    print(\"Adjusted Predicted Age:\", adjusted_age)\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjHO6bV9kMzH",
        "outputId": "4ae4f702-07f2-4eda-8bbe-315e47fe62fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1\n",
            "Actual Age: 46\n",
            "Adjusted Predicted Age: 46\n",
            "\n",
            "Sample 2\n",
            "Actual Age: 24\n",
            "Adjusted Predicted Age: 56\n",
            "\n",
            "Sample 3\n",
            "Actual Age: 28\n",
            "Adjusted Predicted Age: 48\n",
            "\n",
            "Sample 4\n",
            "Actual Age: 49\n",
            "Adjusted Predicted Age: 45\n",
            "\n",
            "Sample 5\n",
            "Actual Age: 70\n",
            "Adjusted Predicted Age: 50\n",
            "\n",
            "Sample 6\n",
            "Actual Age: 42\n",
            "Adjusted Predicted Age: 49\n",
            "\n",
            "Sample 7\n",
            "Actual Age: 64\n",
            "Adjusted Predicted Age: 58\n",
            "\n",
            "Sample 8\n",
            "Actual Age: 51\n",
            "Adjusted Predicted Age: 55\n",
            "\n",
            "Sample 9\n",
            "Actual Age: 59\n",
            "Adjusted Predicted Age: 60\n",
            "\n",
            "Sample 10\n",
            "Actual Age: 64\n",
            "Adjusted Predicted Age: 54\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save(\"age_prediction_model.h5\")\n",
        "\n",
        "# Print confirmation message\n",
        "print(\"Model saved successfully!\")\n"
      ],
      "metadata": {
        "id": "v8rWohZ1kgSz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e13fef28-d1db-4c34-f7d0-e506a31285d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ]
}